---
title: "Introduction to Statistics"
subtitle: "Data, Models & Probability Theory"
author: "Peter Levy"
date: "UKCEH Edinburgh </br> `r Sys.Date()`"
format:
  revealjs:
    theme: [default, ceh.scss]  
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/logo/UKCEH-Logo_Short_Positive_RGB.png
---


```{r render, eval = FALSE, include=FALSE}
# use quarto installed with Rstudio; set path first time
# Sys.setenv(QUARTO_PATH="C:/Program Files/RStudio/resources/app/bin/quarto/bin/quarto.exe")
renv::install("leaflet")
library(quarto)
quarto_render("./index.qmd")
```

## What we will cover {.smaller}
- terminology
- probability theory - why the normal distribution is "normal"
- linear regression and friends (GLM, GLMM, GAM, ...?#!)
- p values and null-hypothesis testing - why it is often a bad idea
- Machine Learning - "statistics on steroids"
- the Bayesian mind meld.

# Terminology {background="#37a635"}

## The main problem with statistics
::: columns
::: {.column width="50%"}
Like learning to tell the time:

- "*A day is 24 hours: 12 in the day, 12 in the night.*"
- "*If the big hand points to One, that's Five past.*"
- "*The third hand is the second hand.*"
:::

::: {.column width="50%"}
{{< video https://youtu.be/u5puzYBgaXM?t=147 
 height="200%"
>}}
:::
:::

## What is "*Statistics*"?
Different uses of the word:

- reporting "states" - crop yield, unemployment, population size
- summarising information - mean, median, variability
- analysing data so as to draw conclusions
- applying probability theory to data

## Terminology
- hypothesis = a statement of how a system works
    - e.g. CO$_2$ causes global warming
- model = mathematical representation of how a system works
    - e.g. Temperature = f(CO$_2$)
- parameter = numerical constant within a model
    - e.g. $T = \beta  CO_2$
    - true value unknown, but estimated with uncertainty

## Science and Models
The core of the scientific process involves:

- formulating models of how the world works
- comparing with data to assess their validity

**Inference** is the process of estimating models, parameters, and their uncertainties, using data

- how we go from evidence to aÂ conclusion

## Science and Models
::: columns
::: {.column width="50%"}
*Conditional probability* is the logic underpinning all science.
:::

::: {.column width="50%"}
![](images/jaynes.png){width=100mm}
:::
:::

## **Not** about ...
trying to remember which "test" to use when.

::: columns
::: {.column width="50%"}
- t-test & ANOVA
- regression
- General Linear Model
- Generalised Linear Model
:::

::: {.column width="50%"}
- mixed-effects models
- GLMMs
- GAMs
- kriging
:::
:::

## Some concepts
- variability
- error - how far measurements or models are from the truth
- uncertainty - how precisely we know a quantity

All can be represented as probability distributions.



## Likelihood and probability
"*Likelihood*" and "*probability*" used interchangeably in common speech.

Likelihood has a specific meaning in statistics:

- parameters have a likelihood:
- equal to the probability of the data, given those parameters
- $L[\mu, \sigma] = P[\mathrm{data} | \mu, \sigma]$


## Confusion is normal
::: incremental
![](images/confusion.png){fig-align="center" width="650"}

- Get comfortable with confusion
- Ask questions!
:::

## Bayesian Methods for Ecological and Environmental Modelling
A 4-day course on applying conditional probability:

[https://nerc-ceh.github.io/beem/](https://nerc-ceh.github.io/beem/)


# The Normal Distribution {background="#37a635"}
## Terminology
- the Normal Distribution
- the Gaussian Distribution
- the Bell Curve
- the "Central Limit Theorem"
    - states conditions where things are "normal"
    
All the same thing.

## 
![](images/be-normal-tshirt.png)


## Practical
Demonstrating where the Normal Distribution comes from.

- Go to: [https://github.com/NERC-CEH/stats_intro/tree/master/R](https://github.com/NERC-CEH/stats_intro/tree/master/R)

Download raw file & run: `R/simulate_normal_dist.R`

-   a function to average random numbers


``` {.r code-line-numbers="2|3|4"}
# function to add n uniform random_numbers between x_lower and x_upper
average_random_numbers <- function(n_numbers, x_lower = 100, x_upper = 200) {
  random_numbers <- runif(n_numbers, x_lower, x_upper)
  return(mean(random_numbers))
}
```


##
{{< video https://youtu.be/zeJD6dqJ5lo?t=113 
 width="100%" height="100%"
>}}

## Examples of the Normal Distribution
- variability e.g. human height
    - sum of several factors affecting growth
- measurement error
    - sum of several errors affecting accuracy
- uncertainty
    - sum of several terms affecting accuracy


# Linear regression and friends {background="#37a635"}

## Terminology

- Linear Regression
- Linear Models
- Regression modelling
- the General Linear Model includes:
    - t-test
    - ANOVA
    - multivariate regression

::: incremental
We want to predict one thing (*y*) on the basis of another (*x*)
:::

## Terminology

::: columns
::: {.column width="40%"}
-   **y**: response, outcome, dependent variable
-   **x**: predictor, covariate, independent variable - used to help understand the variability in the response
:::

::: {.column width="60%"}
```{r}
#| out.width: "100%"
df <- read.csv(url("https://raw.githubusercontent.com/NERC-CEH/beem_data/main/trees.csv"))
df$basal_area <- pi *(df$dbh / 2)^2
library(ggplot2)
p <- ggplot(data = df, 
       mapping = aes(x = basal_area, y = tree_mass)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(
    x = "Basal area, cm2" , 
    y = "Tree mass, kg"
    )
p
```
:::
:::

## Linear model {#regression-model-1}

A function that describes a linear relationship between the response, $y$, and the predictor, $x$.

$$\begin{aligned} y &= \color{black}{\textbf{Model}} + \text{Error} \\[6pt]
&= \color{black}{\mathbf{f(\theta, x)}} + \epsilon \\[6pt]
&= \mathrm{intercept} + \mathrm{slope} \cdot x + \epsilon \\[6pt] 
&= \alpha + \beta x + \epsilon \\[6pt] 
\theta &= (\alpha, \beta) \\[6pt] 
\end{aligned}$$

## Linear model {#regression-model-2}

A function that describes a linear relationship between the response, $y$, and the predictor, $x$.

$$\begin{aligned} y &= \color{black}{\textbf{Model}} + \text{Error} \\[6pt]
&= \color{black}{\mathbf{f(\theta, x)}} + \epsilon \\[6pt]
&= \mathrm{intercept} + \mathrm{slope} \cdot x + \epsilon \\[6pt] 
&= \beta_0 + \beta_1 x + \epsilon \\[6pt] 
\theta &= (\beta_0, \beta_1) \\[6pt] 
\end{aligned}$$

## Linear model

::: columns
::: {.column width="30%"}
$$
\begin{aligned} y &= \color{purple}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{purple}{\mathbf{f(\theta, x)}} + \epsilon \\[8pt]
&= \color{purple}{\alpha + \beta x} + \epsilon \\[8pt]
\end{aligned}
$$
:::

::: {.column width="70%"}
```{r}
m <- lm(tree_mass ~ basal_area, data = df)

p <- ggplot(data = df, 
       mapping = aes(x = basal_area, y = tree_mass)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(x = "x", y = "y") +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(), 
    axis.ticks.y = element_blank()
    )
p
```
:::
:::

## Linear model + residual error

::: columns
::: {.column width="30%"}
$$\begin{aligned} y &= \color{purple}{\textbf{Model}} + \color{blue}{\textbf{Error}} \\[8pt]
&= \color{purple}{\mathbf{f(\theta, x)}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
&= \color{purple}{\alpha + \beta x} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
 \end{aligned}$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
p + geom_segment(aes(x = basal_area, xend = basal_area, 
                     y = tree_mass, yend = predict(m)), 
                     color = "blue")
```
:::
:::

## Linear model  + residual error

::: columns
::: {.column width="30%"}
$$\begin{aligned} y &= \color{purple}{\textbf{Model}} + \color{blue}{\textbf{Error}} \\[8pt]
&= \color{purple}{\mathbf{f(\theta, x)}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
&= \color{purple}{\alpha + \beta x} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
 \end{aligned}$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
ggplot(df, aes(x = predict(m) - tree_mass)) +
  geom_histogram(alpha = 0.95, fill = "royal blue") + xlab("Residual, kg")
```
:::
:::

## Uses
- Prediction
- Extrapolation
- Associations / correlation
- Causal inference

## Terminology
Regression slopes $\beta$ are often referred to as **effects**

- e.g. $\beta = 1.5$ is the numerical effect of $x$ on $y$ in the model
- but *effect* implies causality
- better called *coefficient* to be neutral

## Frequentist linear regression

- find the best-fit line which minimises residuals
- point estimate for the relationship between *x* and *y*
- assume Gaussian approximation for confidence intervals
- test null hypothesis of zero slope $\beta = 0$

```{r}
#| out.width: "60%"
p <- ggplot(data = df, 
       mapping = aes(x = basal_area, y = tree_mass)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(
    x = "Basal area, cm2" , 
    y = "Tree mass, kg"
    )
p
```

## Bayesian linear regression

- find the (posterior) distribution of plausible relationships between *x* and *y*
    - i.e. $P(\theta | y) \propto P(\theta) P(y | \theta)$
- use Bayes rule via MCMC
- no Gaussian assumption needed for parameters (only measurement error)
- hypothesis test is irrelevant - posterior $\theta$ captures all information


## Assumptions

::: incremental
- **L**inearity
- **0** zero error in $x$
- **I**ndependent samples
- **N**ormally-distributed measurement error
- **C**onstant variance across the range in $x$
- **loth** to forget these
- mnemonic: **L0INCloth**
:::

## Extensions to Linear Modelling

When the assumptions are not met ...

::: incremental
- **L**inearity - Generalised Linear Models; General Additive Models
- **0** zero error in $x$ - uncertainty propagation by MC simulation
- **I**ndependent samples - hierarchical & mixed-effect models; spatial/time series
- **N**ormally-distributed measurement error - Generalised Linear Models
:::


# Measurement and uncertainty {background="#37a635"}

<!--- {Terminology -->
## Terminology for measurements
::: columns
::: incremental
::: {.column width="35%"}
- "The Facts"
- Evidence
- Observations
- Measurements
- Data
:::

::: {.column width="65%"}
:::
:::
:::

## Terminology for measurements
::: columns
::: {.column width="35%"}
- "The Facts"
- Evidence
- Observations
- Measurements
- Data
:::

::: {.column width="65%"}
All the same thing, increasing uncertainty.
![](images/down_arrow.png)

:::
:::
<!--- } -->

<!--- {Mmnts are proxies With diagram for simple obs error-->
## Measurements and uncertainty
Measurements are a proxy for true process of interest. 
Connection between the two can be:

::: columns
::: {.column width="50%"}
- sample from population (sampling error)
- imperfect measurements (measurement error)
:::

::: {.column width="50%"}
```{r, fig.width = 4}
library(DiagrammeR)
grViz("
digraph G {
	fontname='Helvetica,Arial,sans-serif'
	node [fontname='Helvetica,Arial,sans-serif']
	edge [fontname='Helvetica,Arial,sans-serif']

	subgraph cluster_0 {
		node [style=filled];
		a3;
		label = 'Observed';
		color=blue
	}

	subgraph cluster_1 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		b3 [dir=back];
		label = 'True \n(unobserved)';
	}

	subgraph cluster_2 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		c3;
		label = 'Error';
	}
  
  a3[label = 'Q@_{obs}'];
  b3[label = 'Q'];  
  c3[label = '\u03c3@_{Q}'];
  
	b3 -> a3;
	c3 -> a3;
}
")
```
:::
:::
<!--- } -->

<!--- {With diagram for proxy obs error 1-->
## Measurements and uncertainty
Measurements are a proxy for true process of interest. 
Connection between the two can be:

::: columns
::: {.column width="50%"}
- proxy variables
    - true variable is hard to measure but can be approximated
:::

::: {.column width="50%"}
```{r, fig.width = 4}
grViz("
digraph G {
	fontname='Helvetica,Arial,sans-serif'
	node [fontname='Helvetica,Arial,sans-serif']
	edge [fontname='Helvetica,Arial,sans-serif']

	subgraph cluster_0 {
		node [style=filled];
		a2 -> a3 [style = 'dotted', arrowhead = 'none'];
		label = 'Observed';
		color=blue
	}

	subgraph cluster_1 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		b2 -> b3 [dir=back];
		label = 'True \n(unobserved)';
	}

	subgraph cluster_2 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		c2 -> c3 [style = 'invis'];
		label = 'Error';
	}
  
  a2[label = 'h@_{obs}'];
  a3[label = 'Q@_{obs}'];
  
  b2[label = 'h'];
  b3[label = 'Q'];  

  c2[label = '\u03c3@_{h}'];
  c3[label = '\u03c3@_{Q}'];
  
	b2 -> a2;
	c2 -> a2;
	b3 -> a3;
	c3 -> a3;
}
")
```
:::
:::
<!--- } -->

<!--- {An example:-->
## Measuring stream flow

![\label{fig:streamgauge} The stream flow rate $Q$ is the product of the stream cross-sectional area and its velocity. A pressure transducer continuously records stream height $h$ via the pressure, $P_{\mathrm{stream}}$.](images/streamgauge1.png)

<!--- } -->

<!--- {Streamflow example -->
## Measuring streamflow
>- We would typically say we have "measurements of streamflow"
>- But we actually have measurements of stream height
>- or rather water pressure ...
>- or rather pressure transducer output voltage ...
>- or rather data logger measurements of voltage.
<!--- } -->

<!--- {Streamflow example -->
## Streamflow example
We have a series of four linear models:

\begin{align*}
Q_{flow}   =& \beta_1 + \beta_2 h_{stream} + \epsilon_1 \\
h_{stream} =& \beta_3 + \beta_4 P_{sensor} + \epsilon_2 \\
P_{sensor} =& \beta_5 + \beta_6 V_{sensor} + \epsilon_3 \\
V_{sensor} =& \beta_7 + \beta_8 V_{logger} + \epsilon_4
\end{align*}

We effectively assume these models are perfect and the error terms $\epsilon$ 1-4 are zero.

This is a relatively simple case, and some of these errors may well be negligible.
Many cases are not so simple.
<!--- } -->

<!--- {Streamflow example -->
## Streamflow example
We can substitute one model in another:

\begin{align*}  \label{eq:strr}
Q_{flow}   =& \beta_1 + \beta_2 (\beta_3 + \beta_4 P_{sensor} + \epsilon_2) + \epsilon_1 \\
P_{sensor} =& \beta_5 + \beta_6 V_{sensor} + \epsilon_3 \\
V_{sensor} =& \beta_7 + \beta_8 V_{logger} + \epsilon_4
\end{align*}

to give a single model:

\begin{align*}  \label{eq:stream3}
Q_{flow} = \beta_1 +& \beta_2 (\beta_3 + \beta_4 (\beta_5 + \beta_6 (\beta_7 + \beta_8 V_{logger}  \\
         +& \epsilon_4) + \epsilon_3) + \epsilon_2) + \epsilon_1
\end{align*}
<!--- } -->

<!--- {With diagram for proxy obs error 3 -->
## Measurements and uncertainty
Measurements are a proxy for true process of interest. Connection between the two can be:

::: columns
::: {.column width="50%"}
- proxy variables
    - true variable is hard to measure but can be approximated
:::

::: {.column width="50%"}
```{r, fig.width = 4}
grViz("
digraph G {
	fontname='Helvetica,Arial,sans-serif'
	node [fontname='Helvetica,Arial,sans-serif']
	edge [fontname='Helvetica,Arial,sans-serif']

	subgraph cluster_0 {
		node [style=filled];
		a0 -> a1 -> a2 -> a3 [style = 'dotted', arrowhead = 'none'];
		label = 'Observed';
		color=blue
	}

	subgraph cluster_1 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		b0 -> b1 -> b2 -> b3 [dir=back];
		label = 'True \n(unobserved)';
	}

	subgraph cluster_2 {
		style=filled;
		color=lightgrey;
		node [style=filled,color=white];
		c0 -> c1 -> c2 -> c3 [style = 'invis'];
		label = 'Error';
	}
  
  a0[label = 'V@_{obs}'];
  a1[label = 'P@_{obs}'];
  a2[label = 'h@_{obs}'];
  a3[label = 'Q@_{obs}'];
  
  b0[label = 'V'];
  b1[label = 'P'];
  b2[label = 'h'];
  b3[label = 'Q'];  

  c0[label = '\u03c3@_{V}'];
  c1[label = '\u03c3@_{P}'];
  c2[label = '\u03c3@_{h}'];
  c3[label = '\u03c3@_{Q}'];
  
	b0 -> a0;
	c0 -> a0;
	b1 -> a1;
	c1 -> a1;
	b2 -> a2;
	c2 -> a2;
	b3 -> a3;
	c3 -> a3;
}
")
```
:::
:::
<!--- } -->

<!--- {Upscaling -->
## Uncertainty in upscaling
Often, true process of interest is a larger-scale property (e.g. annual sum, regional mean)

::: columns
::: {.column width="50%"}
- integration 
- interpolation / extrapolation, 
- accounting for small-scale heterogeneity
- adds additional modelling steps
:::

::: {.column width="50%"}
![](images/Crichton_Fn2o_bubblePlot_byDate.png)
:::
:::
<!--- } -->

<!--- {Ignoring -->
## Ignoring measurement error has consequences
But uncertainty often not propagated. Leads to results with:

1. under-reported random uncertainty
    - inflated effect size
    - low statistical power
        - *P*(finding effect when present)
        - but over-reported
    
## Ignoring measurement error has consequences
But uncertainty often not propagated. Leads to results with:

2. under-reported systematic uncertainty
    - unacknowledged biases
    - distorted results, systematic artefacts
    - high false positive rate
        - *P*(finding effect when none present)
        - but under-reported
<!--- } -->

<!--- {Ignoring -->
## Ignoring measurement error has consequences
But uncertainty often not propagated. Leads to:

::: incremental
- high "false discovery rate"
    - *P*(claiming to find effect when none present)
- biased results in literature 
- flawed meta-analyses
- the "reproducibility crisis"
:::
<!--- } -->

<!--- {Ignoring -->
## The Reproducibility Crisis

![\label{fig:Ioannidis2005} https://doi.org/10.1371/journal.pmed.0020124](images/Ioannidis2005.png)
<!--- } -->

<!--- {reproducibility crisis -->
## *"Why most published research findings are false"*

High "false discovery rates", often much higher than 5 %.

In ecology, these stem from:

- unpropagated measurement error
- unacknowledged measurement bias
- low prevalence of effects
    - i.e. prior $P(\mathrm{effect})$ is small
<!--- } -->

# Understanding false discovery rates {background="#37a635"}

## Covid testing    
![](images/false_discovery_covid.png)
    
## Land use change from EO
![](images/false_discovery_luc.png)

## Generic experiments    
![](images/false_discovery_expt_1.png)
        
## Generic experiments
![](images/false_discovery_expt_2.png)
        
## Generic experiments: low power  
![](images/false_discovery_expt_3.png)
        
## Experiments: low prevalence
![](images/false_discovery_expt_4.png)
        
## Practical

Prove it to yourself:

[https://nerc-ceh.github.io/beem/ae/ae-6a-measurements.html](https://nerc-ceh.github.io/beem/ae/ae-6a-measurements.html)
